---
title: "Revealing the Personal Effects of Nutrition with Mixed-Effect Bayesian Network"
author:
- Jari Turkia, jari.turkia@cgi.com
- University of Eastern Finland
bibliography: biblio.bib
output:
  html_document: default
  pdf_document: default
abstract: This notebook describes the implementation of the modelling method and the experimental analysis that is described in the main article.
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE, fig.align="center")

# this allows using tikz rendering for plots with "dev=tikz"
knit_hooks$set(plot = function(x, options) {
  if ('tikz' %in% options$dev && !options$external) {
    hook_plot_tex(x, options)
  } else hook_plot_md(x, options)
})

# Load common MEBN package
source("mebn/MEBN.r")
```

### Predicting personal blood test levels

So far we have explored the dataset by using all the information available. For getting more confidence for the model, we use k-fold cross validation to predict the blood test values based on personal nutrition information. It is likely that the previous model is overfitted to the dataset and it may decrade predicting performance for new and unseen data.

In following, we use 5-fold cross validation where the patients in the dataset are splitted to five distinct sets and the model is estimated by holding out always one of these sets. This holdout set is then used as a prediction target. For those patients we know the true blood test values and it allows us to calculate the prediction performance score.

First, we prepare the 10-fold datasets for training and testing. It is important that all observations for one patient are included either in training or testing. This is taken care of by "kfold_split_stratified" function in LOO package.

```{r 5-fold split, message=FALSE, warning=FALSE}
library(loo)
set.seed(345)
fold5_indexes <- kfold_split_stratified(K = 106, x = sysdimet$SUBJECT_ID)
#table(sysdimet$SUBJECT_ID, fold5_indexes)
```


To overcome the possible overfitting, we apply the Finnish horseshoe, a shrinkage prior, on regression coefficients. It allows specifying a prior knowledge, or at least an educated guess, about the number of significant predictors for a target. Here we guess that one third of the nutrients might be relevant for any given blood test, and apply following parameters for the shrinkage

```{r shrinkage_parameters, echo=TRUE, message=FALSE, warning=FALSE}
shrinkage_parameters <- within(list(),
{
    scale_icept  <- 1         # prior std for the intercept
    scale_global <- 0.01825   # scale for the half-t prior for tau: 
                              # ((p0=6) / (D=22-6)) * (sigma / sqrt(n=106*4))
    nu_global    <- 1         # degrees of freedom for the half-t priors for tau
    nu_local     <- 1         # degrees of freedom for the half-t priors for lambdas
    slab_scale   <- 1         # slab scale for the regularized horseshoe
    slab_df      <- 1         # slab degrees of freedom for the regularized horseshoe           
})
```

Next we fit the previous model with the Finnish horseshoe added. Besides the shrinkage parameters, we provide now the data in two sets: input data for estimation and target data to hold out for prediction. First contains 4/5 of the data and the latter 1/5. We gather the predictions later to asses the prediction performance.

```{r, echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
library(loo)
source("mebn/MEBN.r")
#remove("models_BLMM_gamma_ar1_pred_1_fshdl_blmm")

initial_graph <- mebn.new_graph_with_randomvariables(datadesc)

folds <- seq(1,106)

# index of holdout partition (TODO: loop)
h <- 36

holdout_idx <- fold5_indexes %in% h
training_idx <- fold5_indexes %in% folds[-h]

holdout_data <- sysdimet[holdout_idx,]
training_data <- sysdimet[training_idx,]

sysdimet_gamma_ar1_rhs <- mebn.bipartite_model(reaction_graph = initial_graph, 
                                   inputdata = training_data,
                                   targetdata = holdout_data,
                                   predictor_columns = assumedpredictors, 
                                   assumed_targets = assumedtargets, 
                                   group_column = "SUBJECT_ID",
                                   local_estimation = mebn.sampling,
                                   local_model_cache = paste0("models/BLMM_gamma/ar1_rhs_pred/", h), 
                                   stan_model_file = "mebn/BLMM_gamma_ar1_rhs_pred.stan",
                                   reg_params = shrinkage_parameters,
                                   normalize_values = TRUE)
```

```{r}
#remove("models_BLMM_gamma_ar1_rhs_pred_1_fshdl_blmm")
source("mebn/MEBN.r")
library(rstan)
library(bayesplot)
  
fit1  <- mebn.get_localfit("BLMM_gamma/ar1_rhs_pred/36/fshdl")

fshdl.true <- holdout_data$fshdl
pred_post <- extract(fit1, pars = c("Y_pred"))
post_50 <- na.omit(pred_post$Y_pred[seq(2000,4000,10),])

fshdl.true
colMeans(na.omit(pred_post$Y_pred))

# Can we predict how this person reacts? What nutrients increase or decrease values on average?

#ppc_dens_overlay(fshdl.true, post_50) + 
#coord_cartesian(xlim = c(0,5.0)) +
#ggtitle("fshdl S36")

```

Bayes R2

```{r}

# Andrew Gelman, Ben Goodrich, Jonah Gabry, and Aki Vehtari (2018). R-squared for Bayesian regression models. The American Statistician
# https://doi.org/10.1080/00031305.2018.1549100
# https://avehtari.github.io/bayes_R2/bayes_R2.html (supplement notebook)

bayes_R2 <- function(y, ypred) {
  e <- -1 * sweep(ypred, 2, y)
  var_ypred <- apply(ypred, 1, var)
  var_e <- apply(e, 1, var)
  var_ypred / (var_ypred + var_e)
}

R2 <- bayes_R2(fshdl.true, na.omit(pred_post$Y_pred))
print(median(R2))
```


And then we test again how the shrinked model fits, and does its predictive score improve from non-shrinked model 

```{r normal_model_ppc, echo=FALSE, eval=TRUE}
mebn.target_dens_overlays("BLMM_gamma/ar1_rhs_pred/1", assumedtargets[assumedtargets$Name=="fshdl",], sysdimet)
```

```{r, ar1_rhs_loo}
library(loo)

assumedtargets <- assumedtargets[assumedtargets$Name=="fshdl",]
nonrhs_vs_rhs <- mebn.LOO_comparison(assumedtargets, "BLMM_gamma/ar1_pred/1", "BLMM_gamma/ar1_rhs_pred/1")
nonrhs_vs_rhs
```





### Personal prediction

Finally, we can hold out a set of data for group of patients and test the predictive ability of the model. Let's calculate the model with a training set and do predictions for this separate test set.











```{r}
person23 <- mebn.personal_graph(person_id = 23, initial_graph, assumedpredictors, assumedtargets, "BLMM_gamma/ar1/")
```

```{r, personal_variations_figure, fig.height = 7, fig.width = 7, fig.align = "center"}
mebn.plot_personal_effects(person23, 5)
```



### Henkilökohtaisten ennusteiden varmuus

Kaikkien estimoitujen henkilökohtaisten vaikutusten 95%-luottamusvälit sisältävät nollan. Tässä on kuitenkin esimerkkejä voimakkaimmista. Valitaan joku potilas edellä löydetystä ryhmästä 1 eli keskimäärin voimakkaammin insuliinilla reagoivista.

```{r, echo=FALSE, eval=FALSE}
library(bayesplot)

# Datan visuaalisen tarkastelun perusteella tämän henkilön insuliinitaso nousi selvästi 
# proteiinin saannin myötä

subject_id <- 46   # tumman sininen

protein_id <- match("prot", datadesc$Name)

fsins_blmm <- mebn.get_localfit("fsins")
posterior <- as.array(fsins_blmm)

prot_plot <- mcmc_areas(posterior, pars = paste0("personal_effect[",subject_id,",",protein_id,"]"), prob = 0.50, prob_outer = 0.95, point_est = "mean") + ylab("todennäköisyys") + ggtitle("proteiini - insuliini (S46)") +
  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank())

prot_plot

posterior
```

```{r, echo=FALSE, eval=FALSE}

#sysdimet[sysdimet$effect_group == 1,]$SUBJECT_ID
subject_id <- 46

sakkar_id <- match("sakkar", datadesc$Name)
hhydr_id <- match("hhydr", datadesc$Name)

fsins_blmm <- mebn.get_localfit("fsins")
posterior <- as.array(fsins_blmm)

sakkar_plot <- mcmc_areas(posterior, pars = paste0("personal_effect[",subject_id,",",sakkar_id,"]"), prob = 0.50, prob_outer = 0.95, point_est = "mean") + ylab("todennäköisyys") + ggtitle("sakkaroosi") +
  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank())

hhydr_plot <- mcmc_areas(posterior, pars = paste0("personal_effect[",subject_id,",",hhydr_id,"]"), prob = 0.50, prob_outer = 0.95, point_est = "mean") + ylab("todennäköisyys") + ggtitle("hiilihydraatti") +
  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank())

bayesplot_grid(plots = list(sakkar_plot, hhydr_plot), legends = FALSE)

```









Temporal material.. remove


```{r, echo=FALSE, eval=FALSE}

## Comparing normal and gamma regressions.. absolute parameters should match?

  library(bayesplot)
  library(rstan)

  fshdl_norm <- mebn.get_localfit("BLMM_normal/fshdl")
  fshdl_gamma <- mebn.get_localfit("BLMM_gamma/fshdl")
  fsins_gamma <- mebn.get_localfit("BLMM_gamma/ar1/fsins")
  fsins_ln <- mebn.get_localfit("BLMM_lognormal/fsins")

  fshdl_gamma <- mebn.get_localfit("BLMM_gamma/hierarchical_idlink/fshdl")

  fshdl.true <- sysdimet$fshdl
  fsins.true <- sysdimet$fsins
  fpgluk.true <- sysdimet$fpgluk

  posterior_n <- extract(fshdl_norm, pars = c("Y_rep", "beta", "beta_Intercept", "sigma_e"))
  posterior_g <- extract(fshdl_gamma, pars = c("Y_rep", "beta", "beta_Intercept"))
  posterior_g <- extract(fsins_gamma, pars = c("Y_rep", "beta", "beta_Intercept"))
  posterior_ln <- extract(fsins_ln, pars = c("Y_rep", "beta", "beta_Intercept", "sigma_e"))
  
  mean(posterior_n$beta_Intercept)
  mean(posterior_g$beta_Intercept)
  
  mean(posterior_n$beta[2])
  
  print(fshdl_norm, pars=c("beta_Intercept", "beta", "sigma_b", "sigma_e"))
  print(fsins_ln, pars=c("beta_Intercept", "beta", "sigma_b", "sigma_e"))
  print(fsins_gamma, pars=c("beta_Intercept", "beta", "sigma_b", "sigma_e"))

  posterior_n_50 <- posterior_n$Y_rep[1:50,]
  posterior_ln_50 <- posterior_ln$Y_rep[1:50,]

  posterior_g <- extract(fshdl_gamma, pars = c("Y_rep", "beta", "beta_Intercept"))
  posterior_g_50 <- posterior_g$Y_rep[1:50,]

    ppc_dens_overlay(fshdl.true, posterior_n_50) + 
   coord_cartesian(xlim = c(0,10.0)) +
    ggtitle("Veren HDL-kolestrolin normaali-jakauma")
  
  # Back to original scale 
  #fshdl.nrep <- mebn.rescale(posterior_n_50, mean(fshdl.true))
  #fshdl.grep <- mebn.rescale(posterior_g_50, mean(fshdl.true))
  fsins.grep <- mebn.rescale(posterior_g_50, mean(fshdl.true))
  
  ppc_dens_overlay(fshdl.true, posterior_n_50) + 
   coord_cartesian(xlim = c(0,10.0)) +
    ggtitle("Veren HDL-kolestrolin normaali-jakauma")
  
#  ppc_dens_overlay(fshdl.true, fshdl.grep) + 
#  coord_cartesian(xlim = c(0,10.0)) +
#  ggtitle("Veren HDL-kolestrolin gamma-jakauma")

  ppc_dens_overlay(fshdl.true, posterior_g_50) + 
    coord_cartesian(xlim = c(0,10.0)) +
    ggtitle("Veren HDL-kolestrolin gamma-jakauma")

  ppc_dens_overlay(fsins.true, posterior_g_50) + 
    coord_cartesian(xlim = c(0,30.0)) +
    ggtitle("Veren insuliinin gamma-jakauma")

  ppc_dens_overlay(fpgluk.true, posterior_g_50) + 
    coord_cartesian(xlim = c(0,10.0)) +
    ggtitle("Veren glukoosin gamma-jakauma")

  ppc_dens_overlay(fsins.true, posterior_ln_50) + 
    coord_cartesian(xlim = c(0,50.0)) +
    ggtitle("Veren insuliinin lognormal-jakauma")
  
```


```{r}
remove("models_BLMM_gamma_ar1_fsins_blmm")
source("mebn/MEBN.r")
  
fit  <- mebn.get_localfit("BLMM_gamma/ar1/fsins")
ms <- summary(fit, pars=c("beta_Intercept", "beta", "sigma_b", "sigma_e"), probs=c(0.10, 0.90))
ms

su <- mebn.localsummary(fsins_gamma)
su$fixef_lCI[21]

                                                value = localsummary$fixef[p], 
                                                value_lCI = localsummary$fixef_lCI[p],
                                                value_uCI = localsummary$fixef_uCI[p],


```






```{r}
#library("shinystan")
#gamma1 <- mebn.get_localfit("BLMM_gamma/ar1/fsins")
#launch_shinystan(gamma1)
```



```{r, echo=FALSE, eval=FALSE}
library(bayesplot)

fpgluk_normal <- mebn.get_localfit("BLMM_normal/fpgluk")
fpgluk_gamma <- mebn.get_localfit("BLMM_gamma/hierarchical_idlink/fpgluk")

fsins_normal <- mebn.get_localfit("BLMM_normal/fsins")
fsins_gamma_ar1 <- mebn.get_localfit("BLMM_gamma/ar1/fsins")

normal_plot <- plot(fpgluk_normal)
gamma_plot <- plot(fpgluk_gamma)

bayesplot_grid(plots = list(normal_plot, gamma_plot), legends = FALSE)

summary(fsins_gamma_ar1)

```

```{r}
# Compare intercepts

posterior_n <- extract(fsins_normal, pars = c("beta_Intercept", "beta", "sigma_e"))
posterior_g <- extract(fsins_gamma_ar1, pars = c("beta_Intercept", "beta", "sigma_e"))

mean(posterior_n$beta_Intercept) # 12
mean(posterior_g$beta_Intercept) # -9

#colMeans(posterior_n$beta)
#colMeans(posterior_g$beta)


```

## Pruning the graph

Fit of the local distributions is now reasonable well for considering the graphical model that it describes. For gaining better nutritional insight and improving the model generalization, we should still prune out insignificant nutrients and holding only most relevant as edges of the graph.

Vehtari and Piiroinen () provided a good overview of Bayesian model selection methods. First, we apply the Finnish horseshoe, a shrinkage prior, on regression coefficients. It allows specifying a prior knowledge, or at least an educated guess, about the number of significant predictors for a target. Here we guess that one third of the nutrients might be relevant for any given blood test, and apply following parameters for the shrinkage

```{r shrinkage_parameters, echo=TRUE, message=FALSE}
shrinkage_parameters <- within(list(),
{
    scale_icept  <- 1         # prior std for the intercept
    scale_global <- 0.01825   # scale for the half-t prior for tau: 
                              # ((p0=6) / (D=22-6)) * (sigma / sqrt(n=106*4))
    nu_global    <- 1         # degrees of freedom for the half-t priors for tau
    nu_local     <- 1         # degrees of freedom for the half-t priors for lambdas
    slab_scale   <- 1         # slab scale for the regularized horseshoe
    slab_df      <- 1         # slab degrees of freedom for the regularized horseshoe           
})
```

Next we fit the previous model with the Finnish horseshoe added

```{r, echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
source("mebn/MEBN.r")

initial_graph <- mebn.new_graph_with_randomvariables(datadesc)
sysdimet_gamma_ar1_rhs <- mebn.bipartite_model(reaction_graph = initial_graph, 
                                   inputdata = sysdimet,
                                   predictor_columns = assumedpredictors, 
                                   assumed_targets = assumedtargets, 
                                   group_column = "SUBJECT_ID",
                                   local_estimation = mebn.sampling,
                                   local_model_cache = "models/BLMM_gamma/ar1_rhs", 
                                   stan_model_file = "mebn/BLMM_gamma_ar1_rhs.stan",
                                   reg_params = shrinkage_parameters,
                                   normalize_values = TRUE)
```

And then we test again how the shrinked model fits, and does its predictive score improve from non-shrinked model 

```{r normal_model_ppc, echo=FALSE, eval=TRUE}
mebn.target_dens_overlays("BLMM_gamma/ar1_rhs/", assumedtargets, sysdimet)
```

```{r, ar1_rhs_loo}
nonrhs_vs_rhs <- mebn.LOO_comparison(assumedtargets, "BLMM_gamma/ar1", "BLMM_gamma/ar1_rhs")
nonrhs_vs_rhs
```

Unfortunately, a visual comparison of PPCS show bias in model fits. This is further confirmed by a LOO comparison that shows little to significant drawbacks in prediction performance.

Thus, we discard the RHS model and proceed with previous full model with AR(1) structure. Projection method is shown to be a good for finding relevant model in the model space (viite). It seeks to find a minimal model that has 95% of predictive power of a full model.

The method has been implemented in projpred package 

```{r projpred}

## TODO: Repeat this for all local model in the graph

# Test with BLMM_gamma/ar1/fshdl 
target_column <- assumedtargets[assumedtargets$Name=="fshdl",]

# Get parameters that we used to fit the previous model
params <- mebn.set_model_parameters(assumedpredictors, target_column, group_column = "SUBJECT_ID", inputdata = sysdimet, normalize_values = TRUE)

# Initialize a reference model for variable selection

refm <- init_refmodel(z = params$X, 
                      y = params$Y, 
                      gaussian(), 
                      predfun = mebn.linpred, 
                      dis = sysdimet_gamma_ar1,
                      offset = NULL, 
                      intercept = TRUE,
                      cvfun = NULL, 
                      cvfits = NULL)




```
