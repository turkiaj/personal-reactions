---
title: "Personal Effects of Nutrition"
output:
  html_document: default
  word_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE, fig.align="center")

# Load common MEBN package
source("mebn/MEBN.r")
```

This notebook provides a reproducible analysis of the nutrional effects that is the main contribution of the article. The companying article provides more theory, but the experimental part elaborated here in detail.

With the effects of nutrition we mean the amount of variance in person's blood test values that can be explained with different nutrients in his or her past diet. Beside the nutrients, also personal details, like age, gender, and medication, can affect the blood test values that we can chosen to reflect the personal well-being. 

We propose that this system can be plausible modelled with a directed graph where nutrients and other predictors may affect one or several blood test values. More precisely, we consider Bayesian networks that can model this system as a joint probability distribution. They cannot contain cycles from target nodes back to their predictors, and thus we leave out all the connections from blood test values back to nutrients. We consider that this is biologically plausible and does not leave out possible models. 

## Data

The dataset in our experiment comes from Sysdimet study. ... variables, data points..

We have collected our prior information at a separate "Data description.csv"-file. For guiding the search for plausible graphs we have indicated which variables are responses at the graph and which are possible predictors affecting them.

```{r load_data, echo=FALSE, message=FALSE}

# Read the data description
datadesc <- read.csv(file="Data description.csv", header = TRUE, sep = ";")

# Read the actual data matching the description
sysdimet <- read.csv(file="data/SYSDIMET_diet.csv", sep=";", dec=",")

# Define how to iterate through the graph
assumedpredictors <- datadesc[datadesc$Order==100,]    
assumedtargets <- datadesc[datadesc$Order==200,] 
```

(explain variables)

**Nutritional effects as Bayesian Network**

Nutrients and their bodily responses are considered as random variables at the graph

```{r}
initial_normal_graph <- mebn.new_graph_with_randomvariables(datadesc)
```


**Assumptions for local distributions**

The joint probability distribition of Bayesian network can constructed from distict local distributions [viite]. Modeling the local distributions.. 

**Constructing the graph**

Edges of the graph are absolute effects of nutrients.

We start from a hierarchical model with normal distribution that estimates of absolute effects are considered as reference when developing the model.

```{r, echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
sysdimet_normal <- mebn.graphical_model(reaction_graph = initial_normal_graph, 
                                         inputdata = sysdimet,
                                         predictor_columns = assumedpredictors, 
                                         assumed_targets = assumedtargets, 
                                         group_column = "SUBJECT_ID",
                                         local_estimation = mebn.sampling,
                                         local_model_cache = "models/BLMM_normal", 
                                         stan_model_file = "mebn/BLMM_normal.stan",
                                         normalize_values = TRUE)

```

**Normal model as reference**

If we now check these initial models of personal blood test responses, we can see that the Gaussian distribution is not a good fit as it allows negative blood test values and does not model the right tail of the true distribution. The estimated model parameters of Gaussian models are still kept as a reference point for further models. Those parameters are the weights of the edges at the Bayesian Network and it is important that all the random variables at the network can work with the same regression coefficients.

```{r normal_model_ppc, echo=FALSE, eval=TRUE}
source("mebn/MEBN.r")
normal_targets <- assumedtargets
normal_targets$ScaleMin <- -10
normal_targets$ScaleMax <- 50

mebn.target_dens_overlays("BLMM_normal/", normal_targets, sysdimet)
```

**Developing the model**

- Biometric data is usually more multiplicative than additive. This is why log-normal distribution makes sense.
  Log-normal / Gamma

```{r, echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
initial_gamma_graph <- mebn.new_graph_with_randomvariables(datadesc)

sysdimet_gamma <- mebn.graphical_model(reaction_graph = initial_gamma_graph, 
                                   inputdata = sysdimet,
                                   predictor_columns = assumedpredictors, 
                                   assumed_targets = assumedtargets, 
                                   group_column = "SUBJECT_ID",
                                   local_estimation = mebn.sampling,
                                   local_model_cache = "models/BLMM_gamma/hierarchical_idlink", 
                                   stan_model_file = "mebn/BLMM_gamma_hierarchical.stan",
                                   normalize_values = TRUE)
```

## Checking the fit of the local models

```{r gamma_ppc, echo=FALSE, eval=TRUE}
mebn.target_dens_overlays("BLMM_gamma/hierarchical_idlink/", assumedtargets, sysdimet)
```

```{r effect_comparison}

# TODO: Make function: mebn.compare_typicals(bn1, bn2) returns this table

# - find beta nodes of both normal and gamma distributions 
normal_nodes <- V(sysdimet_normal)
n_beta <- normal_nodes[normal_nodes$type=="beta"]

gamma_nodes <- V(sysdimet_gamma)
g_beta <- gamma_nodes[gamma_nodes$type=="beta"]

# - construct a table for comparing the estimates
typical_effects<-data.frame(matrix(NA, nrow=length(n_beta), ncol=0))

typical_effects$effect <- unlist(lapply(strsplit(gsub("beta_","", n_beta$name), "_"), function(x) paste0(toString(datadesc[datadesc$Name==x[1],]$Description)," -> ", toString(datadesc[datadesc$Name==x[2],]$Description))))

typical_effects$normal_estimate <- round(n_beta$value,6)
typical_effects$gamma_estimate <- round(g_beta$value,6)

# we see that typical effects are exactly the same in absolute scale
typical_effects

```

**Comparing different local models with LOO**

Besides the visual inspection, we can also compare the models using LOO-PSIS information criteria. It uses log probability that is calculated as part of the Stan models.

```{r, normal_gamma_loo}
source("mebn/MEBN.r")

target_variables <- assumedtargets
graphdir1 <- "BLMM_normal/"
graphdir2 <- "BLMM_gamma/hierarchical_idlink/"

comparison<-data.frame(matrix(NA, nrow=nrow(target_variables), ncol=3))
comparison$graph1 <- graphdir1
comparison$graph2 <- graphdir2
comparison$ELDP_LOO <- 0.0
comparison$ELDP_LOO_SE <- 0.0

for (targetname in target_variables$Name)
{
  dist <- "fshdl"
  m1 <- mebn.get_localfit(paste0(graphdir1, dist))
  m2 <- mebn.get_localfit(paste0(graphdir2, dist))

  m1_loglik <- extract_log_lik(m1, merge_chains = FALSE)
  m1_rel_n_eff <- relative_eff(exp(m1_loglik))
  m1_loo <- loo(m1_loglik, r_eff = m1_rel_n_eff, cores = 4)
  
  m2_loglik <- extract_log_lik(m2, merge_chains = FALSE)
  m2_rel_n_eff <- relative_eff(exp(m2_loglik))
  m2_loo <- loo(m2_loglik, r_eff = m2_rel_n_eff, cores = 4)
  
  l1 <- paste0(graphdir1, targetname)
  l2 <- paste0(graphdir2, targetname)
  
  comp <- c(l1,l2,m) 
  
  elpd <- mebn.LOO_comparison_local(graphdir1,graphdir2,targetname)
  
  
}

# local dist           BLMM_normal       BLMM_gamma/hierarchical_idlink/
# 
# fshdl (LOO/SE)       212 (se)          435
# fshdl (LOO/SE)       212 (se)          435
# fshdl (LOO/SE)       212 (se)          435
# fshdl (LOO/SE)       212 (se)          435



# "The difference will be positive if the expected predictive accuracy for the second model is higher."

```

As the expected log predictive density (ELPD) of gamma model is higher, we should choose that for further development.

##Varying response time: AR-structures##

```{r, echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}

sysdimet_gamma_ar1 <- mebn.graphical_model(reaction_graph = initial_graph, 
                                   inputdata = sysdimet,
                                   predictor_columns = assumedpredictors, 
                                   assumed_targets = assumedtargets, 
                                   group_column = "SUBJECT_ID",
                                   local_estimation = mebn.sampling,
                                   local_model_cache = "models/BLMM_gamma/ar1", 
                                   stan_model_file = "mebn/BLMM_gamma_ar1.stan",
                                   normalize_values = TRUE)
```

```{r gamma_ar1_ppc, echo=FALSE, eval=TRUE}
mebn.target_dens_overlays("BLMM_gamma/ar1/")
```

```{r, gamma_ar1_loo}
mebn.
library(loo)

# TODO: LOO Compare BNs
#list.files("models/BLMM_gamma/hierarchical_idlink")

m1 <- mebn.get_localfit("BLMM_gamma/hierarchical_idlink/fshdl")
m2 <- mebn.get_localfit("BLMM_gamma/ar1/fshdl")

m1_loglik <- extract_log_lik(m1, merge_chains = FALSE)
m1_rel_n_eff <- relative_eff(exp(m1_loglik))
m1_loo <- loo(m1_loglik, r_eff = m1_rel_n_eff, cores = 4)

print(m1_loo)

m2_loglik <- extract_log_lik(m2, merge_chains = FALSE)
m2_rel_n_eff <- relative_eff(exp(m2_loglik))
m2_loo <- loo(m2_loglik, r_eff = m2_rel_n_eff, cores = 4)

print(m2_loo)

# "The difference will be positive if the expected predictive accuracy for the second model is higher."
print(compare(m1_loo, m2_loo), digits = 3)

```


# TODO: AR table
library(rstan)
fshdl_ar1 <- mebn.get_localfit("BLMM_gamma/ar1/fshdl")
post_hdl <- extract(fshdl_ar1, pars = c("ar1"))

mean(post_hdl$ar1) # 0.08868632

fsins_ar1 <- mebn.get_localfit("BLMM_gamma/ar1/fsins")
postins <- extract(fsins_ar1, pars = c("ar1"))

mean(postins$ar1) # -0.01187752

```


- Pruning insignificant nutrients with a horseshow prior. Projpred could be also used.


```{r shrinkage_parameters, echo=FALSE, message=FALSE}
shrinkage_parameters <- within(list(),
{
    scale_icept  <- 1         # prior std for the intercept
    scale_global <- 0.01825   # scale for the half-t prior for tau: 
                              # ((p0=6) / (D=22-6)) * (sigma / sqrt(n=106*4))
    nu_global    <- 1         # degrees of freedom for the half-t priors for tau
    nu_local     <- 1         # degrees of freedom for the half-t priors for lambdas
    slab_scale   <- 1         # slab scale for the regularized horseshoe
    slab_df      <- 1         # slab degrees of freedom for the regularized horseshoe           
})
```

```{r}
initial_graph <- mebn.new_graph_with_randomvariables(datadesc)
```


```{r, echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}

sysdimet_gamma_ar1_rhs <- mebn.graphical_model(reaction_graph = initial_graph, 
                                   inputdata = sysdimet,
                                   predictor_columns = assumedpredictors, 
                                   assumed_targets = assumedtargets, 
                                   group_column = "SUBJECT_ID",
                                   local_estimation = mebn.sampling,
                                   local_model_cache = "models/BLMM_gamma/ar1_rhs", 
                                   stan_model_file = "mebn/BLMM_gamma_ar1_rhs.stan",
                                   reg_params = shrinkage_parameters,
                                   normalize_values = TRUE)
```

```{r normal_model_ppc, echo=FALSE, eval=TRUE}
mebn.target_dens_overlays("BLMM_gamma/ar1_rhs/")
```


## Pruning the graph

- Remove the insignicant components: more informative graph and multiresponse
- TODO: use projpred to remove edges


### Principal components as graph visualiation

After finding a reasonable fit, we can analyze the principal components that explain the variation.

```{r, echo=TRUE, message=TRUE}
sysdimet_visgraph <- mebn.visualization_graph(sysdimet_gamma_ar1_rhs)

# Filter only the most significant edges having large typical effect or large personal variance
alledges <- E(sysdimet_visgraph)
top_neg_edges <- head(alledges[order(alledges$weight)], 15)
top_pos_edges <- head(alledges[order(-alledges$weight)], 15)
top_pers_edges <- head(alledges[order(-alledges$b_sigma)], 15)

# Comment out this row to see all the connections at the model
sysdimet_visgraph <- delete.edges(sysdimet_visgraph, alledges[-c(top_neg_edges, top_pos_edges, top_pers_edges)])

# Write the MEBN in GEXF format for visualization
mebn.write_gexf(sysdimet_visgraph, "sysdimet.gexf")

# Load the graph stored in gexf-file as pass it to JavaScript visualization as a string
gexf_file <- file("sysdimet.gexf") 
graph_string <- paste(readLines(gexf_file), collapse = "")
```

<script>
  var sysdimet_graph = '`r graph_string`';
</script>

<!-- the graph is drawn in this container. variable 'sysdimet_graph' is hard coded to contain the gexf-string -->
<div id="sigmacontainer"></div>

```{r, echo=FALSE, message=FALSE}
# Load the graph drawing JavaScript
htmltools::includeHTML("population_graph.htm")
```
</br>

## Inference

Rest of the notebook consideres the inference that we can do with previously estimated mixed-effect bayesian network.

First we do exploration over the whole sample population for finding clusters of similarly behaving patients. Then in the last part we show how we can predict personal nutritional effects for individual patients.

TODO: tämän läpikäynnin voisi tehdä verkon rakennuksen yhteydessä

```{r ppc, echo=FALSE, eval=FALSE}
library(rstan)
library(bayesplot)
library(ggplot2)

theme_set(bayesplot::theme_default())

personal_variations_from_mean <- matrix(NA, ncol=nrow(assumedpredictors)*nrow(assumedtargets), nrow=length(levels(sysdimet$SUBJECT_ID)))
personal_effects <- matrix(NA, ncol=nrow(assumedpredictors)*nrow(assumedtargets), nrow=length(levels(sysdimet$SUBJECT_ID)))
personal_effects_quantiles <- matrix(NA, ncol=3, nrow=106*22*5)

dens_plots <- list()
i <- 1

for (targetname in assumedtargets$Name)
{
  target_blmm <- mebn.get_localfit(targetname)
  true_value <- as.vector(sysdimet[,targetname])

  posterior <- extract(target_blmm, pars = c("Y_rep", "personal_effect", "b", "ar1"))
  posterior_y_50 <- posterior$Y_rep[1:50,]
  
  # Back to original scale 
  post.rep <- mebn.rescale(posterior_y_50, mean(true_value))

  b_blmm <- colMeans(posterior$b)
  beta_b_blmm <- colMeans(posterior$personal_effect)
  
  pe <- summary(target_blmm, pars="personal_effect", probs = c(0.25, 0.75))$summary[,c(1,4,5)]
  
  if (i == 1) {
    # variance of the intercept is omitted
    personal_variations_from_mean <- b_blmm[,2:dim(b_blmm)[2]]
    personal_effects <- beta_b_blmm
    personal_effects_quantiles <- pe
  }
  else
  {
    personal_variations_from_mean <- cbind(personal_variations_from_mean, b_blmm[,2:dim(b_blmm)[2]])
    personal_effects <- cbind(personal_effects, beta_b_blmm)
    personal_effects_quantiles <- rbind(pe)
  }

  dens_plots[[i]] <- ppc_dens_overlay(true_value, post.rep) + 
    coord_cartesian(xlim = c(assumedtargets[assumedtargets$Name == targetname,]$ScaleMin,assumedtargets[assumedtargets$Name == targetname,]$ScaleMax)) +
    ggtitle(targetname)
  
  i <- i + 1
}

bayesplot_grid(plots = dens_plots, legends = FALSE)
```



## Piileviä reagointitapojen ryhmiä

```{r, echo=FALSE, eval=FALSE}
library(stats)
library(gridExtra)

k.max <- 8
wss_effects <- sapply(1:k.max, function(k){kmeans(personal_effects, k, nstart=50, iter.max = 15)$tot.withinss})
wss_vars <- sapply(1:k.max, function(k){kmeans(personal_variations_from_mean, k, nstart=50, iter.max = 15)$tot.withinss})

df_vars <- data.frame(x = 1:k.max, y = wss_vars)
df_effects <- data.frame(x = 1:k.max, y = wss_effects)

plot1 <- ggplot(data=df_effects, aes(x=x, y=y, group=1)) +
  geom_line() +
  geom_point() + 
  ggtitle("Eri tavoin reagoivia ryhmiä") +
  xlab("Ryhmien määrä") +
  ylab("Ryhmien välinen ero")

plot2 <- ggplot(data=df_vars, aes(x=x, y=y, group=1)) +
  geom_line() +
  geom_point() + 
  ggtitle("Poikkeama tyypillisestä") +
  xlab("Ryhmien määrä") +
  ylab("Ryhmien välinen ero")

gridExtra::grid.arrange(plot1,plot2,nrow=1)
```

### Kuinka tyypillisestä reagointitavasta poiketaan

Tässä kaavion X-akselin nollakohdassa on kyseisen reagointitavan tyypillinen tai keskimääräinen arvo, ja palkit kuvaavat löydettyjen ryhmien poikkeamaa tästä keskiarvosta.

```{r variation clusters, echo=FALSE, eval=FALSE}
km <- kmeans(personal_variations_from_mean, centers = 4)

sysdimet$variation_group <- km$cluster # mihin klusteriin kukin potilas kuuluu. vertaa tätä esimerkiksi geeneihin

variations_data <- as.data.frame(t(km$centers))
variations_data$predictor <- rep(assumedpredictors$Description,nrow(assumedtargets))

cl <- rep(1,22)
t_idx <- c(cl,cl+1,cl+2,cl+3,cl+4)

variations_data$response <- assumedtargets$Description[t_idx]
effect_levels <- paste0(variations_data$predictor," -> ", variations_data$response)

variations_data$effect <- factor(effect_levels, levels=effect_levels)

# Yhteenlaskettu vaikutus kaikissa klustereissa
variations_data$overall_effect <- abs(variations_data$'1')+abs(variations_data$'2')+abs(variations_data$'3')+abs(variations_data$'4')

# Suodata näistä vain suurimmat näkyviin
variations_data.filtered <- variations_data[variations_data$overall_effect > 0.002,]

# Piirtoa varten eri klustereiden arvot samaan sarakkeeseen ja oma kenttä merkitsemään klusteria

plot_data <- variations_data.filtered[c("effect")]
plot_data$amount <- variations_data.filtered$'1'
plot_data$cluster <- 1

temp_data <- variations_data.filtered[c("effect")]
temp_data$amount <- variations_data.filtered$'2'
temp_data$cluster <- 2

plot_data <- rbind(plot_data, temp_data)

temp_data <- variations_data.filtered[c("effect")]
temp_data$amount <- variations_data.filtered$'3'
temp_data$cluster <- 3

plot_data <- rbind(plot_data, temp_data)

temp_data <- variations_data.filtered[c("effect")]
temp_data$amount <- variations_data.filtered$'4'
temp_data$cluster <- 4

plot_data <- rbind(plot_data, temp_data)

plot_data$compared_to_typical <- ifelse(plot_data$amount < 0, "below", "above")

ggplot(plot_data, aes(x=effect, y=amount)) + 
  geom_bar(stat='identity', aes(fill=compared_to_typical), width=.5, show.legend = FALSE) +
  coord_flip() +
  theme(axis.title.x = element_blank(), axis.title.y = element_blank()) +
  facet_wrap(~cluster)

```

### Reagointitapojen ryhmiä

Tässä ryhmittelyä on tehty itse vaikutuksen perusteella.

```{r effect clusters, echo=FALSE, eval=FALSE}
km <- kmeans(personal_effects, centers = 4)

sysdimet$effect_group <- km$cluster # mihin klusteriin kukin potilas kuuluu. vertaa tätä esimerkiksi geeneihin

variations_data <- as.data.frame(t(km$centers))
variations_data$predictor <- rep(assumedpredictors$Description,nrow(assumedtargets))

cl <- rep(1,22)
t_idx <- c(cl,cl+1,cl+2,cl+3,cl+4)

variations_data$response <- assumedtargets$Description[t_idx]
effect_levels <- paste0(variations_data$predictor," -> ", variations_data$response)

variations_data$effect <- factor(effect_levels, levels=effect_levels)

# Yhteenlaskettu vaikutus kaikissa klustereissa
variations_data$overall_effect <- abs(variations_data$'1')+abs(variations_data$'2')+abs(variations_data$'3')+abs(variations_data$'4')

# Suodata näistä vain suurimmat näkyviin
variations_data.filtered <- variations_data[variations_data$overall_effect > 0.004,]

# Piirtoa varten eri klustereiden arvot samaan sarakkeeseen ja oma kenttä merkitsemään klusteria

plot_data <- variations_data.filtered[c("effect")]
plot_data$amount <- variations_data.filtered$'1'
plot_data$cluster <- 1

temp_data <- variations_data.filtered[c("effect")]
temp_data$amount <- variations_data.filtered$'2'
temp_data$cluster <- 2

plot_data <- rbind(plot_data, temp_data)

temp_data <- variations_data.filtered[c("effect")]
temp_data$amount <- variations_data.filtered$'3'
temp_data$cluster <- 3

plot_data <- rbind(plot_data, temp_data)

temp_data <- variations_data.filtered[c("effect")]
temp_data$amount <- variations_data.filtered$'4'
temp_data$cluster <- 4

plot_data <- rbind(plot_data, temp_data)

plot_data$effect_direction <- ifelse(plot_data$amount > 0, "lowers", "raises")

ggplot(plot_data, aes(x=effect, y=amount)) + 
  geom_bar(stat='identity', aes(fill=effect_direction), width=.7, show.legend = FALSE) +
  coord_flip() +
  theme(axis.title.x = element_blank(), axis.title.y = element_blank()) +
  facet_wrap(~cluster)
```


### Personal prediction

Finally, we can hold out a set of data for group of patients and test the predictive ability of the model. Let's calculate the model with a training set and do predictions for this separate test set.

### Personal graph

Similar to the population level graph, we can now predict a personal graphs that indicate how nutrients affect their blood values.

```{r, echo=TRUE, message=TRUE}
library(rstan)
source("mebn/MEBN.r")

initial_graph <- mebn.new_graph_with_randomvariables(datadesc)

p37_graph <- mebn.personal_graph(reaction_graph = initial_graph, 
                                   person_id = 37,
                                   predictor_columns = assumedpredictors, 
                                   assumed_targets = assumedtargets)

# Write the MEBN in GEXF format for visualization
mebn.write_gexf(p37_graph, "p37.gexf")

# Load the graph stored in gexf-file as pass it to JavaScript visualization as a string
gexf_file <- file("p37.gexf") 
graph_string <- paste(readLines(gexf_file), collapse = "")
```

<script>
  var sysdimet_graph = '`r graph_string`';
</script>

<!-- the graph is drawn in this container. variable 'sysdimet_graph' is hard coded to contain the gexf-string -->
<div id="sigmacontainer"></div>

```{r, echo=FALSE, message=FALSE}
# Load the graph drawing JavaScript
htmltools::includeHTML("population_graph.htm")
```
</br>



### Henkilökohtaisten ennusteiden varmuus

Kaikkien estimoitujen henkilökohtaisten vaikutusten 95%-luottamusvälit sisältävät nollan. Tässä on kuitenkin esimerkkejä voimakkaimmista. Valitaan joku potilas edellä löydetystä ryhmästä 1 eli keskimäärin voimakkaammin insuliinilla reagoivista.

```{r, echo=FALSE, eval=FALSE}
library(bayesplot)

# Datan visuaalisen tarkastelun perusteella tämän henkilön insuliinitaso nousi selvästi 
# proteiinin saannin myötä

subject_id <- 46   # tumman sininen

protein_id <- match("prot", datadesc$Name)

fsins_blmm <- mebn.get_localfit("fsins")
posterior <- as.array(fsins_blmm)

prot_plot <- mcmc_areas(posterior, pars = paste0("personal_effect[",subject_id,",",protein_id,"]"), prob = 0.50, prob_outer = 0.95, point_est = "mean") + ylab("todennäköisyys") + ggtitle("proteiini - insuliini (S46)") +
  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank())

prot_plot

posterior
```

```{r, echo=FALSE, eval=FALSE}

#sysdimet[sysdimet$effect_group == 1,]$SUBJECT_ID
subject_id <- 46

sakkar_id <- match("sakkar", datadesc$Name)
hhydr_id <- match("hhydr", datadesc$Name)

fsins_blmm <- mebn.get_localfit("fsins")
posterior <- as.array(fsins_blmm)

sakkar_plot <- mcmc_areas(posterior, pars = paste0("personal_effect[",subject_id,",",sakkar_id,"]"), prob = 0.50, prob_outer = 0.95, point_est = "mean") + ylab("todennäköisyys") + ggtitle("sakkaroosi") +
  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank())

hhydr_plot <- mcmc_areas(posterior, pars = paste0("personal_effect[",subject_id,",",hhydr_id,"]"), prob = 0.50, prob_outer = 0.95, point_est = "mean") + ylab("todennäköisyys") + ggtitle("hiilihydraatti") +
  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank())

bayesplot_grid(plots = list(sakkar_plot, hhydr_plot), legends = FALSE)

```

Temporal material.. remove


```{r, echo=FALSE, eval=FALSE}

## Comparing normal and gamma regressions.. absolute parameters should match?

  library(bayesplot)
  library(rstan)

  fshdl_norm <- mebn.get_localfit("BLMM_normal/fshdl")
  fshdl_gamma <- mebn.get_localfit("BLMM_gamma/fshdl")
  fsins_gamma <- mebn.get_localfit("BLMM_gamma/ar1/fsins")
  fsins_ln <- mebn.get_localfit("BLMM_lognormal/fsins")

  fshdl_gamma <- mebn.get_localfit("BLMM_gamma/hierarchical_idlink/fshdl")

  fshdl.true <- sysdimet$fshdl
  fsins.true <- sysdimet$fsins
  fpgluk.true <- sysdimet$fpgluk

  posterior_n <- extract(fshdl_norm, pars = c("Y_rep", "beta", "beta_Intercept", "sigma_e"))
  posterior_g <- extract(fshdl_gamma, pars = c("Y_rep", "beta", "beta_Intercept"))
  posterior_g <- extract(fsins_gamma, pars = c("Y_rep", "beta", "beta_Intercept"))
  posterior_ln <- extract(fsins_ln, pars = c("Y_rep", "beta", "beta_Intercept", "sigma_e"))
  
  mean(posterior_n$beta_Intercept)
  mean(posterior_g$beta_Intercept)
  
  mean(posterior_n$beta[2])
  
  print(fshdl_norm, pars=c("beta_Intercept", "beta", "sigma_b", "sigma_e"))
  print(fsins_ln, pars=c("beta_Intercept", "beta", "sigma_b", "sigma_e"))
  print(fsins_gamma, pars=c("beta_Intercept", "beta", "sigma_b", "sigma_e"))

  posterior_n_50 <- posterior_n$Y_rep[1:50,]
  posterior_ln_50 <- posterior_ln$Y_rep[1:50,]
  posterior_g_50 <- posterior_g$Y_rep[1:50,]
  
  # Back to original scale 
  #fshdl.nrep <- mebn.rescale(posterior_n_50, mean(fshdl.true))
  #fshdl.grep <- mebn.rescale(posterior_g_50, mean(fshdl.true))
  fsins.grep <- mebn.rescale(posterior_g_50, mean(fshdl.true))
  
  ppc_dens_overlay(fshdl.true, posterior_n_50) + 
   coord_cartesian(xlim = c(0,10.0)) +
    ggtitle("Veren HDL-kolestrolin normaali-jakauma")
  
#  ppc_dens_overlay(fshdl.true, fshdl.grep) + 
#  coord_cartesian(xlim = c(0,10.0)) +
#  ggtitle("Veren HDL-kolestrolin gamma-jakauma")

  ppc_dens_overlay(fshdl.true, posterior_g_50) + 
    coord_cartesian(xlim = c(0,10.0)) +
    ggtitle("Veren HDL-kolestrolin gamma-jakauma")

  ppc_dens_overlay(fsins.true, posterior_g_50) + 
    coord_cartesian(xlim = c(0,30.0)) +
    ggtitle("Veren insuliinin gamma-jakauma")

  ppc_dens_overlay(fpgluk.true, posterior_g_50) + 
    coord_cartesian(xlim = c(0,10.0)) +
    ggtitle("Veren glukoosin gamma-jakauma")

  ppc_dens_overlay(fsins.true, posterior_ln_50) + 
    coord_cartesian(xlim = c(0,50.0)) +
    ggtitle("Veren insuliinin lognormal-jakauma")
  
```



```{r}
#library("shinystan")
#gamma1 <- mebn.get_localfit("BLMM_gamma/ar1/fsins")
#launch_shinystan(gamma1)
```



```{r, echo=FALSE, eval=FALSE}
library(bayesplot)

fpgluk_normal <- mebn.get_localfit("BLMM_normal/fpgluk")
fpgluk_gamma <- mebn.get_localfit("BLMM_gamma/hierarchical_idlink/fpgluk")

fsins_normal <- mebn.get_localfit("BLMM_normal/fsins")
fsins_gamma_ar1 <- mebn.get_localfit("BLMM_gamma/ar1/fsins")

normal_plot <- plot(fpgluk_normal)
gamma_plot <- plot(fpgluk_gamma)

bayesplot_grid(plots = list(normal_plot, gamma_plot), legends = FALSE)

```

```{r}
# Compare intercepts

posterior_n <- extract(fsins_normal, pars = c("beta_Intercept", "beta", "sigma_e"))
posterior_g <- extract(fsins_gamma_ar1, pars = c("beta_Intercept", "beta", "sigma_e"))

mean(posterior_n$beta_Intercept) # 12
mean(posterior_g$beta_Intercept) # -9

#colMeans(posterior_n$beta)
#colMeans(posterior_g$beta)


```

